# -*- coding: utf-8 -*-
"""AIMLDL PROJECT MODEL .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vHt8a8s1KU6jyNkcR479xVWhQcWzXp7w
"""
pip install numpy pandas scikit-learn tensorflow matplotlib seaborn lime shap scipy

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from lime import lime_tabular
import warnings
warnings.filterwarnings('ignore')

print("Ready to go!")

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

def create_multiclass_fall_data(n_samples=1000, n_features=6, random_state=42):
    """
    Generates synthetic multiclass fall detection data.

    Args:
        n_samples (int): Total number of samples to generate.
        n_features (int): Number of sensor features (e.g., 3 for accelerometer, 3 for gyroscope).
        random_state (int): Seed for random number generation.

    Returns:
        tuple: X (np.array), y (np.array), class_names (list)
    """
    np.random.seed(random_state)

    # Define class names
    class_names = ['Walking', 'Standing', 'Falling']
    n_classes = len(class_names)

    X = []
    y = []

    # Generate data for each class
    for class_idx, class_name in enumerate(class_names):
        num_samples_per_class = n_samples // n_classes

        if class_name == 'Walking':
            # Simulate rhythmic movement
            time = np.linspace(0, 2 * np.pi * num_samples_per_class / 50, num_samples_per_class)
            accel_x = np.sin(time * 2) + np.random.normal(0, 0.1, num_samples_per_class)
            accel_y = np.cos(time * 2) + np.random.normal(0, 0.1, num_samples_per_class)
            accel_z = 9.8 + np.sin(time) + np.random.normal(0, 0.1, num_samples_per_class)
            gyro_x = 0.5 * np.sin(time) + np.random.normal(0, 0.05, num_samples_per_class)
            gyro_y = 0.5 * np.cos(time) + np.random.normal(0, 0.05, num_samples_per_class)
            gyro_z = np.random.normal(0, 0.05, num_samples_per_class)
        elif class_name == 'Standing':
            # Simulate static position with slight variations
            accel_x = np.random.normal(0, 0.05, num_samples_per_class)
            accel_y = np.random.normal(0, 0.05, num_samples_per_class)
            accel_z = 9.8 + np.random.normal(0, 0.05, num_samples_per_class) # Gravity
            gyro_x = np.random.normal(0, 0.01, num_samples_per_class)
            gyro_y = np.random.normal(0, 0.01, num_samples_per_class)
            gyro_z = np.random.normal(0, 0.01, num_samples_per_class)
        elif class_name == 'Falling':
            # Simulate a fall: sudden change in acceleration, followed by impact
            fall_duration = num_samples_per_class // 10 # A short event within the sample block
            accel_x = np.random.normal(0, 0.1, num_samples_per_class)
            accel_y = np.random.normal(0, 0.1, num_samples_per_class)
            accel_z = 9.8 + np.random.normal(0, 0.1, num_samples_per_class)

            # Simulate a quick drop and impact
            accel_z[fall_duration:2*fall_duration] -= 5 # Sudden drop
            accel_z[2*fall_duration:3*fall_duration] += 15 # Impact
            accel_x[fall_duration:2*fall_duration] += np.random.uniform(-3, 3, fall_duration)
            accel_y[fall_duration:2*fall_duration] += np.random.uniform(-3, 3, fall_duration)

            gyro_x = np.random.normal(0, 0.1, num_samples_per_class)
            gyro_y = np.random.normal(0, 0.1, num_samples_per_class)
            gyro_z = np.random.normal(0, 0.1, num_samples_per_class)

        features = np.vstack([accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z]).T
        X.append(features)
        y.extend([class_idx] * num_samples_per_class)

    X = np.vstack(X)
    y = np.array(y)

    # Shuffle data
    indices = np.arange(len(y))
    np.random.shuffle(indices)
    X = X[indices]
    y = y[indices]

    # Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    return X_scaled, y, class_names

'/content/Fall-Detection-Novel-Complete.md'
'create_multiclass_fall_data()'
X, y, class_names = create_multiclass_fall_data(n_samples=2000)
print(f" Dataset: {X.shape}")
print(f"Classes: {class_names}")

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Reshape data to (num_samples, timesteps, features) for Conv1D
# Here, features become timesteps, and we add a channel dimension
X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_val_scaled = X_val_scaled.reshape(X_val_scaled.shape[0], X_val_scaled.shape[1], 1)
X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

# Use num_classes=len(class_names) for consistency
y_train_cat = to_categorical(y_train, num_classes=len(class_names))
y_val_cat = to_categorical(y_val, num_classes=len(class_names))
y_test_cat = to_categorical(y_test, num_classes=len(class_names))

print("Data ready!")

model = Sequential([
    Conv1D(32, 3, activation='relu', input_shape=(X_train_scaled.shape[1], 1), padding='same'), # Corrected input_shape
    MaxPooling1D(2), Dropout(0.2),
    Conv1D(64, 3, activation='relu', padding='same'),
    MaxPooling1D(2), Dropout(0.2),
    Conv1D(128, 3, activation='relu', padding='same'),
    MaxPooling1D(1), Dropout(0.3), # Adjusted MaxPooling for smaller sequence length
    Flatten(),
    Dense(256, activation='relu'), Dropout(0.3),
    Dense(128, activation='relu'), Dropout(0.2),
    Dense(len(class_names), activation='softmax') # Use len(class_names) for output units
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print("Model built!")
print(model.summary())

early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)

history = model.fit(
    X_train_scaled, y_train_cat,
    epochs=100, batch_size=32,
    validation_data=(X_val_scaled, y_val_cat),
    callbacks=[early_stop], verbose=1
)

print("Training done!")

y_test_pred = model.predict(X_test_scaled, verbose=0)
y_test_pred_labels = np.argmax(y_test_pred, axis=1)

test_acc = accuracy_score(y_test, y_test_pred_labels)
print(f"\nTest Accuracy: {test_acc*100:.2f}%")

cm = confusion_matrix(y_test, y_test_pred_labels)
print(f"\nConfusion Matrix:\n{cm}")

print("\nClassification Report:")
print(classification_report(y_test, y_test_pred_labels,
                          target_names=class_names))

fig, axes = plt.subplots(1, 2, figsize=(14, 4))
axes[0].plot(history.history['accuracy'], label='Train')
axes[0].plot(history.history['val_accuracy'], label='Val')
axes[0].set_title('Accuracy', fontweight='bold')
axes[0].legend()
axes[1].plot(history.history['loss'], label='Train')
axes[1].plot(history.history['val_loss'], label='Val')
axes[1].set_title('Loss', fontweight='bold')
axes[1].legend()
plt.tight_layout()
plt.savefig('training.png', dpi=300)
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names)
plt.title('Confusion Matrix', fontweight='bold')
plt.ylabel('True')
plt.xlabel('Predicted')
plt.tight_layout()
plt.savefig('confusion.png', dpi=300)
plt.show()

print("Plots saved!")

print("\n" + "="*70)
print("LIME EXPLAINABILITY (YOUR NOVEL CONTRIBUTION)")
print("="*70)

# Flatten data for LIME
X_test_flat = X_test_scaled.reshape(X_test_scaled.shape[0], -1)
X_train_flat = X_train_scaled.reshape(X_train_scaled.shape[0], -1)

# Create LIME explainer
explainer = lime_tabular.LimeTabularExplainer(
    X_train_flat,
    mode='classification',
    class_names=class_names, # Corrected: Removed .values() and list()
    verbose=False,
    random_state=42
)

# Predict function
def predict_fn(X):
    return model.predict(X.reshape(-1, X_train_scaled.shape[1], 1), verbose=0) # Corrected reshape to match model input

# Find a misclassified FALL sample
fall_indices = np.where(y_test == 2)[0] # Assuming 'Falling' is class index 2
misclassified_fall = None

for idx in fall_indices:
    if y_test_pred_labels[idx] != 2:  # Misclassified fall
        misclassified_fall = idx
        break

if misclassified_fall is not None:
    predicted_label_idx = y_test_pred_labels[misclassified_fall]
    print(f"\n Explaining Misclassified Fall (Sample {misclassified_fall}):")
    print(f"   True: {class_names[y_test[misclassified_fall]]}")
    print(f"   Predicted: {class_names[predicted_label_idx]}")

    exp = explainer.explain_instance(
        X_test_flat[misclassified_fall],
        predict_fn,
        num_features=len(X.T),
        labels=[predicted_label_idx] # Explicitly request explanation for the predicted label
    )

    print(f"\nTop Features Influencing Prediction:")
    for i, (feature, weight) in enumerate(exp.as_list(label=predicted_label_idx)[:5]):
        print(f"   {i+1}. {feature}: {weight:.4f}")

    fig = exp.as_pyplot_figure()
    plt.title('LIME Explanation', fontweight='bold')
    plt.tight_layout()
    plt.savefig('lime_explanation.png', dpi=300)
    plt.show()
else:
    print(" No misclassified falls found - model is excellent!")

    # Explain correct fall instead
    # Ensure there are fall samples in the test set to explain
    if len(fall_indices) > 0:
        correct_fall = fall_indices[0]
        predicted_label_idx_correct = y_test_pred_labels[correct_fall]
        print(f"\n Explaining Correctly Detected Fall (Sample {correct_fall}):")
        print(f"   Confidence: {np.max(y_test_pred[correct_fall])*100:.2f}%")

        exp = explainer.explain_instance(
            X_test_flat[correct_fall],
            predict_fn,
            num_features=len(X.T),
            labels=[predicted_label_idx_correct]
        )

        print(f"\n Features Driving FALL Detection:")
        for i, (feature, weight) in enumerate(exp.as_list(label=predicted_label_idx_correct)[:5]):
            print(f"   {i+1}. {feature}: {weight:.4f}")

        fig = exp.as_pyplot_figure()
        plt.title('LIME: Correct Fall Detection', fontweight='bold')
        plt.tight_layout()
        plt.savefig('lime_explanation_correct.png', dpi=300)
        plt.show()
    else:
        print("No 'Falling' samples found in test set to explain.")

print("\n LIME Explainability Complete! (This is NOVEL - first fall detection paper to use LIME!)")

model.save('fall_detection_novel.h5')

# Save scaler
import pickle
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("Model and scaler saved!")

import os
import pickle
import pandas as pd
from datetime import datetime
from google.colab import files

import os
import pickle
import pandas as pd
from datetime import datetime
from google.colab import files
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

# Save model in the recommended Keras format
model.save('fall_detection_model.keras')
print("Model saved!")

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("Scaler saved!")

# Calculate metrics explicitly for saving
test_precision = precision_score(y_test, y_test_pred_labels, average='weighted')
test_recall = recall_score(y_test, y_test_pred_labels, average='weighted')
test_f1 = f1_score(y_test, y_test_pred_labels, average='weighted')
test_auc = roc_auc_score(y_test_cat, y_test_pred, multi_class='ovr') # For multiclass probabilities

results_df = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],
    'Score': [test_acc, test_precision, test_recall, test_f1, test_auc]
})
results_df.to_csv('results.csv', index=False)
print("Results saved to CSV!")
